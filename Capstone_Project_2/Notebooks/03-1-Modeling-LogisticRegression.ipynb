{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a1fc4fa",
   "metadata": {},
   "source": [
    "# Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f45eed",
   "metadata": {},
   "source": [
    " - [Logistic Regression](#Logistic-Regression)\n",
    " - [BOW and LogisticRegression](#BOW-and-LogisticRegression)\n",
    " - [Bigram and LogisticRigression](#Bigram-and-LogisticRigression)\n",
    " - [TF-IDF and LogisticRegression](#TF-IDF-and-LogisticRegression)\n",
    " - [TF-IDF, Ngarms and LogisticRegression](#TF-IDF,-Ngarms-and-LogisticRegression)\n",
    " - [GridSearch with BOW and Logistic Regression](#GridSearch-with-BOW-and-Logistic-Regression)\n",
    " - [GridSearch with TF-IDF and Logistic Regression](#GridSearch-with-TF-IDF-and-Logistic-Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecb6316",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e09be6",
   "metadata": {},
   "source": [
    "In the preceding notebook, the initial Logistic Regression model are built and examined. Also, two techniques of Countvectorizer and TF-IDF are employed to vectorize the text. The main goal is to tune the parameters of these two vectorization techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d81150da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce18e424",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>toxic_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>explanation edit make username hardcore metall...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aww match background colour seemingly stuck th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey man really not try edit war guy constantly...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>make real suggestion improvement wonder sectio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sir hero chance remember page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  toxic_type\n",
       "0  explanation edit make username hardcore metall...           0\n",
       "1  aww match background colour seemingly stuck th...           0\n",
       "2  hey man really not try edit war guy constantly...           0\n",
       "3  make real suggestion improvement wonder sectio...           0\n",
       "4                      sir hero chance remember page           0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Library/cleaned_text_train_df.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce2ba140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clean_text    54\n",
       "toxic_type     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fc13158",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "02571e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['clean_text']\n",
    "y = df['toxic_type']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "y_train, y_test = y_train.values, y_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e82aa0d",
   "metadata": {},
   "source": [
    "I start with the bag of word text vectorization in conjunction with the logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c8e7a5",
   "metadata": {},
   "source": [
    "## BOW and LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be955d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaron</th>\n",
       "      <th>ab</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abbreviation</th>\n",
       "      <th>abc</th>\n",
       "      <th>abide</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>abortion</th>\n",
       "      <th>...</th>\n",
       "      <th>young</th>\n",
       "      <th>yourselfgo</th>\n",
       "      <th>youth</th>\n",
       "      <th>youtube</th>\n",
       "      <th>ytmnd</th>\n",
       "      <th>yugoslavia</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zero</th>\n",
       "      <th>zionist</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18679</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4329</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153619</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45013</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93942</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        aa  aaron  ab  abandon  abbreviation  abc  abide  ability  able  \\\n",
       "18679    0      0   0        0             0    0      0        0     0   \n",
       "4329     0      0   0        0             0    0      0        0     0   \n",
       "153619   0      0   0        0             0    0      0        0     0   \n",
       "45013    0      0   0        0             0    0      0        0     0   \n",
       "93942    0      0   0        0             0    0      0        0     0   \n",
       "\n",
       "        abortion  ...  young  yourselfgo  youth  youtube  ytmnd  yugoslavia  \\\n",
       "18679          0  ...      0           0      0        0      0           0   \n",
       "4329           0  ...      0           0      0        0      0           0   \n",
       "153619         0  ...      0           0      0        0      0           0   \n",
       "45013          0  ...      0           0      0        0      0           0   \n",
       "93942          0  ...      0           0      0        0      0           0   \n",
       "\n",
       "        zealand  zero  zionist  zone  \n",
       "18679         0     0        0     0  \n",
       "4329          0     0        0     0  \n",
       "153619        0     0        0     0  \n",
       "45013         0     0        0     0  \n",
       "93942         0     0        0     0  \n",
       "\n",
       "[5 rows x 5000 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features = 5000\n",
    "vectorizer = CountVectorizer(max_features=n_features)\n",
    "train_matrix = vectorizer.fit_transform(X_train)\n",
    "count_array = train_matrix.toarray()\n",
    "bow_train = pd.DataFrame(data=count_array, columns=vectorizer.get_feature_names())\n",
    "bow_train.index = X_train.index\n",
    "bow_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3be832e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = bow_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2df85d4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ab</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abc</th>\n",
       "      <th>abide</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>abortion</th>\n",
       "      <th>absence</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>...</th>\n",
       "      <th>youth</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yugoslav</th>\n",
       "      <th>yugoslavia</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zero</th>\n",
       "      <th>zinc</th>\n",
       "      <th>zionism</th>\n",
       "      <th>zionist</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18491</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9389</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48545</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135944</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114289</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ab  abandon  abc  abide  ability  able  abortion  absence  absolute  \\\n",
       "18491    0        0    0      0        0     0         0        0         0   \n",
       "9389     0        0    0      0        0     0         0        0         0   \n",
       "48545    0        0    0      0        0     0         0        0         0   \n",
       "135944   0        0    0      0        0     0         0        0         0   \n",
       "114289   0        0    0      0        0     0         0        0         0   \n",
       "\n",
       "        absolutely  ...  youth  youtube  yugoslav  yugoslavia  zealand  zero  \\\n",
       "18491            0  ...      0        0         0           0        0     0   \n",
       "9389             0  ...      0        0         0           0        0     0   \n",
       "48545            0  ...      0        0         0           0        0     0   \n",
       "135944           0  ...      0        0         0           0        0     0   \n",
       "114289           0  ...      0        0         0           0        0     0   \n",
       "\n",
       "        zinc  zionism  zionist  zone  \n",
       "18491      0        0        0     0  \n",
       "9389       0        0        0     0  \n",
       "48545      0        0        0     0  \n",
       "135944     0        0        0     0  \n",
       "114289     0        0        0     0  \n",
       "\n",
       "[5 rows x 5000 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features = 5000\n",
    "vectorizer = CountVectorizer(max_features=n_features)\n",
    "test_matrix = vectorizer.fit_transform(X_test)\n",
    "count_array = test_matrix.toarray()\n",
    "bow_test = pd.DataFrame(data=count_array, columns=vectorizer.get_feature_names())\n",
    "bow_test.index = X_test.index\n",
    "bow_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b96fcf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = bow_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee7ca49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  <class 'pandas.core.series.Series'> (159517,)\n",
      "y:  <class 'pandas.core.series.Series'> (159517,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X: \", type(X), X.shape)\n",
    "print(\"y: \", type(y), y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f66ff213",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train:  <class 'numpy.ndarray'> (127613, 5000)\n",
      "y train:  <class 'numpy.ndarray'> (127613,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X train: \", type(X_train), X_train.shape)\n",
    "print(\"y train: \", type(y_train), y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d5bb7909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X test:  <class 'numpy.ndarray'> (31904, 5000)\n",
      "y test:  <class 'numpy.ndarray'> (31904,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X test: \", type(X_test), X_test.shape)\n",
    "print(\"y test: \", type(y_test), y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "947d9c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(solver='lbfgs', max_iter=20000, random_state=1)\n",
    "clf_model = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = clf_model.predict(X_train)\n",
    "\n",
    "y_pred_test = clf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d3e42f53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90     28566\n",
      "           1       0.11      0.10      0.11      3338\n",
      "\n",
      "    accuracy                           0.82     31904\n",
      "   macro avg       0.50      0.50      0.50     31904\n",
      "weighted avg       0.81      0.82      0.82     31904\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Classification Report\")\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7a1b7a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98    114726\n",
      "           1       0.92      0.71      0.80     12887\n",
      "\n",
      "    accuracy                           0.96    127613\n",
      "   macro avg       0.95      0.85      0.89    127613\n",
      "weighted avg       0.96      0.96      0.96    127613\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Classification Report\")\n",
    "print(classification_report(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a245563d",
   "metadata": {},
   "source": [
    "This model predict the non-toxic comments with a high precision. However, it did not perform well in detecting the toxic comments, even for the train set. Recall score of the toxic comments for the train and test datasets are 0.772 and 0.685, respectively.\n",
    "<br> How does Ngrams perform? Let's see!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ffa123",
   "metadata": {},
   "source": [
    "## Bigram and LogisticRigression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b3a330ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able edit</th>\n",
       "      <th>able find</th>\n",
       "      <th>able get</th>\n",
       "      <th>absolutely no</th>\n",
       "      <th>absolutely nothing</th>\n",
       "      <th>abuse power</th>\n",
       "      <th>abusing power</th>\n",
       "      <th>accept appropriate</th>\n",
       "      <th>accept copyright</th>\n",
       "      <th>accept notable</th>\n",
       "      <th>...</th>\n",
       "      <th>yet bitch</th>\n",
       "      <th>yet not</th>\n",
       "      <th>yet still</th>\n",
       "      <th>york city</th>\n",
       "      <th>york times</th>\n",
       "      <th>youbollocks youbollocks</th>\n",
       "      <th>yourselfgo fuck</th>\n",
       "      <th>youtube com</th>\n",
       "      <th>youtube video</th>\n",
       "      <th>ytmnd name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   able edit  able find  able get  absolutely no  absolutely nothing  \\\n",
       "0          0          0         0              0                   0   \n",
       "1          0          0         0              0                   0   \n",
       "2          0          0         0              0                   0   \n",
       "3          0          0         0              0                   0   \n",
       "4          0          0         0              0                   0   \n",
       "\n",
       "   abuse power  abusing power  accept appropriate  accept copyright  \\\n",
       "0            0              0                   0                 0   \n",
       "1            0              0                   0                 0   \n",
       "2            0              0                   0                 0   \n",
       "3            0              0                   0                 0   \n",
       "4            0              0                   0                 0   \n",
       "\n",
       "   accept notable  ...  yet bitch  yet not  yet still  york city  york times  \\\n",
       "0               0  ...          0        0          0          0           0   \n",
       "1               0  ...          0        0          0          0           0   \n",
       "2               0  ...          0        0          0          0           0   \n",
       "3               0  ...          0        0          0          0           0   \n",
       "4               0  ...          0        0          0          0           0   \n",
       "\n",
       "   youbollocks youbollocks  yourselfgo fuck  youtube com  youtube video  \\\n",
       "0                        0                0            0              0   \n",
       "1                        0                0            0              0   \n",
       "2                        0                0            0              0   \n",
       "3                        0                0            0              0   \n",
       "4                        0                0            0              0   \n",
       "\n",
       "   ytmnd name  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "\n",
       "[5 rows x 5000 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features = 5000\n",
    "vectorizer = CountVectorizer(max_features=n_features, ngram_range = (2,2))\n",
    "text_matrix = vectorizer.fit_transform(df.clean_text)\n",
    "count_array = text_matrix.toarray()\n",
    "bow_bi_df = pd.DataFrame(data=count_array, columns=vectorizer.get_feature_names())\n",
    "bow_bi_df.index = df.index\n",
    "bow_bi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "df62fff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = bow_bi_df.values\n",
    "y = df['toxic_type'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6412e277",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "904c5788",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(solver='lbfgs', max_iter=20000, random_state=1)\n",
    "clf_model = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = clf_model.predict(X_train)\n",
    "\n",
    "y_pred_test = clf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3ac897ee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     28566\n",
      "           1       0.79      0.16      0.26      3338\n",
      "\n",
      "    accuracy                           0.91     31904\n",
      "   macro avg       0.85      0.58      0.61     31904\n",
      "weighted avg       0.90      0.91      0.88     31904\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Classification Report\")\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "532a8915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95    114726\n",
      "           1       0.87      0.18      0.29     12887\n",
      "\n",
      "    accuracy                           0.91    127613\n",
      "   macro avg       0.89      0.59      0.62    127613\n",
      "weighted avg       0.91      0.91      0.89    127613\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Classification Report\")\n",
    "print(classification_report(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f0f2cd",
   "metadata": {},
   "source": [
    "Both precision and recall scores of the toxic category are lower than those for the first model. It seems that bigram doesn't perform well.\n",
    "<br> Now, I perform the same process with the TF-IDF vectorization in conjunction with logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc9c6c5",
   "metadata": {},
   "source": [
    "## TF-IDF and LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9ff46d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>ab</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abbreviation</th>\n",
       "      <th>abc</th>\n",
       "      <th>abide</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>abortion</th>\n",
       "      <th>abraham</th>\n",
       "      <th>...</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youth</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yugoslav</th>\n",
       "      <th>yugoslavia</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zero</th>\n",
       "      <th>zionist</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2608</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    aa   ab  abandon  abbreviation  abc  abide  ability  able  abortion  \\\n",
       "0  0.0  0.0      0.0           0.0  0.0    0.0      0.0   0.0       0.0   \n",
       "1  0.0  0.0      0.0           0.0  0.0    0.0      0.0   0.0       0.0   \n",
       "2  0.0  0.0      0.0           0.0  0.0    0.0      0.0   0.0       0.0   \n",
       "3  0.0  0.0      0.0           0.0  0.0    0.0      0.0   0.0       0.0   \n",
       "4  0.0  0.0      0.0           0.0  0.0    0.0      0.0   0.0       0.0   \n",
       "\n",
       "   abraham  ...    york  young  youth  youtube  yugoslav  yugoslavia  zealand  \\\n",
       "0      0.0  ...  0.2608    0.0    0.0      0.0       0.0         0.0      0.0   \n",
       "1      0.0  ...  0.0000    0.0    0.0      0.0       0.0         0.0      0.0   \n",
       "2      0.0  ...  0.0000    0.0    0.0      0.0       0.0         0.0      0.0   \n",
       "3      0.0  ...  0.0000    0.0    0.0      0.0       0.0         0.0      0.0   \n",
       "4      0.0  ...  0.0000    0.0    0.0      0.0       0.0         0.0      0.0   \n",
       "\n",
       "   zero  zionist  zone  \n",
       "0   0.0      0.0   0.0  \n",
       "1   0.0      0.0   0.0  \n",
       "2   0.0      0.0   0.0  \n",
       "3   0.0      0.0   0.0  \n",
       "4   0.0      0.0   0.0  \n",
       "\n",
       "[5 rows x 5000 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features = 5000\n",
    "tfidf = TfidfVectorizer(min_df=10, max_df=0.95, use_idf=True, max_features=n_features)\n",
    "train_tfidf = tfidf.fit_transform(df['clean_text'])\n",
    "tfidf_array = train_tfidf.toarray()\n",
    "tfidf_df = pd.DataFrame(tfidf_array, columns=tfidf.get_feature_names())\n",
    "tfidf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5ad75528",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tfidf_df.values\n",
    "y = df['toxic_type'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a137e808",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "13910632",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(solver='lbfgs', max_iter=20000, random_state=0)\n",
    "clf_model = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = clf_model.predict(X_train)\n",
    "\n",
    "y_pred_test = clf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a65d50b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98     28566\n",
      "           1       0.90      0.64      0.75      3338\n",
      "\n",
      "    accuracy                           0.95     31904\n",
      "   macro avg       0.93      0.81      0.86     31904\n",
      "weighted avg       0.95      0.95      0.95     31904\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Classification Report\")\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7525983e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98    114726\n",
      "           1       0.93      0.66      0.77     12887\n",
      "\n",
      "    accuracy                           0.96    127613\n",
      "   macro avg       0.95      0.83      0.88    127613\n",
      "weighted avg       0.96      0.96      0.96    127613\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Classification Report\")\n",
    "print(classification_report(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2f073b",
   "metadata": {},
   "source": [
    "## TF-IDF, Ngarms and LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "37b1e81b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ability create</th>\n",
       "      <th>able edit</th>\n",
       "      <th>able find</th>\n",
       "      <th>able get</th>\n",
       "      <th>able help</th>\n",
       "      <th>able make</th>\n",
       "      <th>able see</th>\n",
       "      <th>able use</th>\n",
       "      <th>absolutely no</th>\n",
       "      <th>absolutely not</th>\n",
       "      <th>...</th>\n",
       "      <th>yet another</th>\n",
       "      <th>yet no</th>\n",
       "      <th>yet not</th>\n",
       "      <th>yet see</th>\n",
       "      <th>yet still</th>\n",
       "      <th>york city</th>\n",
       "      <th>york times</th>\n",
       "      <th>young man</th>\n",
       "      <th>youtube com</th>\n",
       "      <th>youtube video</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 10000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ability create  able edit  able find  able get  able help  able make  \\\n",
       "0             0.0        0.0        0.0       0.0        0.0        0.0   \n",
       "1             0.0        0.0        0.0       0.0        0.0        0.0   \n",
       "2             0.0        0.0        0.0       0.0        0.0        0.0   \n",
       "3             0.0        0.0        0.0       0.0        0.0        0.0   \n",
       "4             0.0        0.0        0.0       0.0        0.0        0.0   \n",
       "\n",
       "   able see  able use  absolutely no  absolutely not  ...  yet another  \\\n",
       "0       0.0       0.0            0.0             0.0  ...          0.0   \n",
       "1       0.0       0.0            0.0             0.0  ...          0.0   \n",
       "2       0.0       0.0            0.0             0.0  ...          0.0   \n",
       "3       0.0       0.0            0.0             0.0  ...          0.0   \n",
       "4       0.0       0.0            0.0             0.0  ...          0.0   \n",
       "\n",
       "   yet no  yet not  yet see  yet still  york city  york times  young man  \\\n",
       "0     0.0      0.0      0.0        0.0        0.0         0.0        0.0   \n",
       "1     0.0      0.0      0.0        0.0        0.0         0.0        0.0   \n",
       "2     0.0      0.0      0.0        0.0        0.0         0.0        0.0   \n",
       "3     0.0      0.0      0.0        0.0        0.0         0.0        0.0   \n",
       "4     0.0      0.0      0.0        0.0        0.0         0.0        0.0   \n",
       "\n",
       "   youtube com  youtube video  \n",
       "0          0.0            0.0  \n",
       "1          0.0            0.0  \n",
       "2          0.0            0.0  \n",
       "3          0.0            0.0  \n",
       "4          0.0            0.0  \n",
       "\n",
       "[5 rows x 10000 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features = 10000\n",
    "tfidf = TfidfVectorizer(min_df=10, max_df=0.95, use_idf=True, max_features=n_features, ngram_range=(2,2))\n",
    "train_tfidf = tfidf.fit_transform(df['clean_text'])\n",
    "tfidf_array = train_tfidf.toarray()\n",
    "tfidf_df = pd.DataFrame(tfidf_array, columns=tfidf.get_feature_names())\n",
    "tfidf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f0efe031",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tfidf_df.values\n",
    "y = df['toxic_type'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "41425e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7c70e205",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(solver='lbfgs', max_iter=20000, random_state=0)\n",
    "clf_model = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = clf_model.predict(X_train)\n",
    "\n",
    "y_pred_test = clf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e7b13fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     28566\n",
      "           1       0.89      0.17      0.28      3338\n",
      "\n",
      "    accuracy                           0.91     31904\n",
      "   macro avg       0.90      0.58      0.62     31904\n",
      "weighted avg       0.91      0.91      0.88     31904\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Classification Report\")\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d7d36bc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95    114726\n",
      "           1       0.92      0.17      0.29     12887\n",
      "\n",
      "    accuracy                           0.92    127613\n",
      "   macro avg       0.92      0.59      0.62    127613\n",
      "weighted avg       0.92      0.92      0.89    127613\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Classification Report\")\n",
    "print(classification_report(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8e0467",
   "metadata": {},
   "source": [
    "# GridSearch with BOW and Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ab08468a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('countvectorizer', CountVectorizer()), \n",
    "                     ('clf', LogisticRegression(solver='lbfgs', max_iter=20000))])\n",
    "\n",
    "parameters = {\n",
    "    'countvectorizer__max_features': (2500, 5000, 1000, 15000, 20000),\n",
    "    'countvectorizer__ngram_range': ((1,1), (2,2))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "aa017f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(pipeline, parameters, cv=5)\n",
    "X = df.clean_text\n",
    "y = df.toxic_type\n",
    "gs = grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "39791595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('countvectorizer', CountVectorizer(max_features=20000)), ('clf', LogisticRegression(max_iter=20000))]\n"
     ]
    }
   ],
   "source": [
    "print(gs.best_estimator_.steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6b3e4d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_countvectorizer__max_features</th>\n",
       "      <th>param_countvectorizer__ngram_range</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12.174575</td>\n",
       "      <td>1.135326</td>\n",
       "      <td>0.782658</td>\n",
       "      <td>0.019074</td>\n",
       "      <td>20000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'countvectorizer__max_features': 20000, 'coun...</td>\n",
       "      <td>0.956651</td>\n",
       "      <td>0.957059</td>\n",
       "      <td>0.956587</td>\n",
       "      <td>0.956869</td>\n",
       "      <td>0.956995</td>\n",
       "      <td>0.956832</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13.943474</td>\n",
       "      <td>1.724176</td>\n",
       "      <td>1.173358</td>\n",
       "      <td>0.276607</td>\n",
       "      <td>15000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'countvectorizer__max_features': 15000, 'coun...</td>\n",
       "      <td>0.956400</td>\n",
       "      <td>0.956808</td>\n",
       "      <td>0.956117</td>\n",
       "      <td>0.956556</td>\n",
       "      <td>0.956242</td>\n",
       "      <td>0.956425</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.917253</td>\n",
       "      <td>0.646965</td>\n",
       "      <td>0.863884</td>\n",
       "      <td>0.084232</td>\n",
       "      <td>5000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'countvectorizer__max_features': 5000, 'count...</td>\n",
       "      <td>0.955241</td>\n",
       "      <td>0.954645</td>\n",
       "      <td>0.954957</td>\n",
       "      <td>0.954518</td>\n",
       "      <td>0.955396</td>\n",
       "      <td>0.954952</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.529709</td>\n",
       "      <td>1.066831</td>\n",
       "      <td>0.818591</td>\n",
       "      <td>0.064200</td>\n",
       "      <td>2500</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'countvectorizer__max_features': 2500, 'count...</td>\n",
       "      <td>0.953423</td>\n",
       "      <td>0.952733</td>\n",
       "      <td>0.952669</td>\n",
       "      <td>0.952575</td>\n",
       "      <td>0.953484</td>\n",
       "      <td>0.952977</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.349462</td>\n",
       "      <td>0.681444</td>\n",
       "      <td>0.728970</td>\n",
       "      <td>0.021935</td>\n",
       "      <td>1000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'countvectorizer__max_features': 1000, 'count...</td>\n",
       "      <td>0.946433</td>\n",
       "      <td>0.948878</td>\n",
       "      <td>0.946839</td>\n",
       "      <td>0.947560</td>\n",
       "      <td>0.948720</td>\n",
       "      <td>0.947686</td>\n",
       "      <td>0.000979</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15.641600</td>\n",
       "      <td>0.854656</td>\n",
       "      <td>1.029621</td>\n",
       "      <td>0.022725</td>\n",
       "      <td>20000</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>{'countvectorizer__max_features': 20000, 'coun...</td>\n",
       "      <td>0.914211</td>\n",
       "      <td>0.915308</td>\n",
       "      <td>0.913958</td>\n",
       "      <td>0.915682</td>\n",
       "      <td>0.914898</td>\n",
       "      <td>0.914812</td>\n",
       "      <td>0.000648</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17.786582</td>\n",
       "      <td>2.410246</td>\n",
       "      <td>1.149909</td>\n",
       "      <td>0.115855</td>\n",
       "      <td>15000</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>{'countvectorizer__max_features': 15000, 'coun...</td>\n",
       "      <td>0.913177</td>\n",
       "      <td>0.913428</td>\n",
       "      <td>0.912046</td>\n",
       "      <td>0.914334</td>\n",
       "      <td>0.913049</td>\n",
       "      <td>0.913207</td>\n",
       "      <td>0.000734</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.729048</td>\n",
       "      <td>1.523099</td>\n",
       "      <td>1.216547</td>\n",
       "      <td>0.095294</td>\n",
       "      <td>5000</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>{'countvectorizer__max_features': 5000, 'count...</td>\n",
       "      <td>0.909290</td>\n",
       "      <td>0.908131</td>\n",
       "      <td>0.908096</td>\n",
       "      <td>0.909664</td>\n",
       "      <td>0.909382</td>\n",
       "      <td>0.908913</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.834648</td>\n",
       "      <td>0.355110</td>\n",
       "      <td>1.132169</td>\n",
       "      <td>0.035889</td>\n",
       "      <td>2500</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>{'countvectorizer__max_features': 2500, 'count...</td>\n",
       "      <td>0.908538</td>\n",
       "      <td>0.908225</td>\n",
       "      <td>0.906623</td>\n",
       "      <td>0.908692</td>\n",
       "      <td>0.908410</td>\n",
       "      <td>0.908098</td>\n",
       "      <td>0.000753</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15.975378</td>\n",
       "      <td>1.569348</td>\n",
       "      <td>1.271804</td>\n",
       "      <td>0.252898</td>\n",
       "      <td>1000</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>{'countvectorizer__max_features': 1000, 'count...</td>\n",
       "      <td>0.906563</td>\n",
       "      <td>0.907034</td>\n",
       "      <td>0.905902</td>\n",
       "      <td>0.907689</td>\n",
       "      <td>0.906968</td>\n",
       "      <td>0.906831</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "8      12.174575      1.135326         0.782658        0.019074   \n",
       "6      13.943474      1.724176         1.173358        0.276607   \n",
       "2      10.917253      0.646965         0.863884        0.084232   \n",
       "0      10.529709      1.066831         0.818591        0.064200   \n",
       "4       8.349462      0.681444         0.728970        0.021935   \n",
       "9      15.641600      0.854656         1.029621        0.022725   \n",
       "7      17.786582      2.410246         1.149909        0.115855   \n",
       "3      17.729048      1.523099         1.216547        0.095294   \n",
       "1      15.834648      0.355110         1.132169        0.035889   \n",
       "5      15.975378      1.569348         1.271804        0.252898   \n",
       "\n",
       "  param_countvectorizer__max_features param_countvectorizer__ngram_range  \\\n",
       "8                               20000                             (1, 1)   \n",
       "6                               15000                             (1, 1)   \n",
       "2                                5000                             (1, 1)   \n",
       "0                                2500                             (1, 1)   \n",
       "4                                1000                             (1, 1)   \n",
       "9                               20000                             (2, 2)   \n",
       "7                               15000                             (2, 2)   \n",
       "3                                5000                             (2, 2)   \n",
       "1                                2500                             (2, 2)   \n",
       "5                                1000                             (2, 2)   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "8  {'countvectorizer__max_features': 20000, 'coun...           0.956651   \n",
       "6  {'countvectorizer__max_features': 15000, 'coun...           0.956400   \n",
       "2  {'countvectorizer__max_features': 5000, 'count...           0.955241   \n",
       "0  {'countvectorizer__max_features': 2500, 'count...           0.953423   \n",
       "4  {'countvectorizer__max_features': 1000, 'count...           0.946433   \n",
       "9  {'countvectorizer__max_features': 20000, 'coun...           0.914211   \n",
       "7  {'countvectorizer__max_features': 15000, 'coun...           0.913177   \n",
       "3  {'countvectorizer__max_features': 5000, 'count...           0.909290   \n",
       "1  {'countvectorizer__max_features': 2500, 'count...           0.908538   \n",
       "5  {'countvectorizer__max_features': 1000, 'count...           0.906563   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "8           0.957059           0.956587           0.956869           0.956995   \n",
       "6           0.956808           0.956117           0.956556           0.956242   \n",
       "2           0.954645           0.954957           0.954518           0.955396   \n",
       "0           0.952733           0.952669           0.952575           0.953484   \n",
       "4           0.948878           0.946839           0.947560           0.948720   \n",
       "9           0.915308           0.913958           0.915682           0.914898   \n",
       "7           0.913428           0.912046           0.914334           0.913049   \n",
       "3           0.908131           0.908096           0.909664           0.909382   \n",
       "1           0.908225           0.906623           0.908692           0.908410   \n",
       "5           0.907034           0.905902           0.907689           0.906968   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "8         0.956832        0.000185                1  \n",
       "6         0.956425        0.000242                2  \n",
       "2         0.954952        0.000335                3  \n",
       "0         0.952977        0.000393                4  \n",
       "4         0.947686        0.000979                5  \n",
       "9         0.914812        0.000648                6  \n",
       "7         0.913207        0.000734                7  \n",
       "3         0.908913        0.000664                8  \n",
       "1         0.908098        0.000753                9  \n",
       "5         0.906831        0.000588               10  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gs.cv_results_).sort_values('mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e426b6e",
   "metadata": {},
   "source": [
    "# GridSearch with BOW and Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "973a05fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['clean_text']\n",
    "y = df['toxic_type']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "39152a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('countvectorizer', CountVectorizer()), \n",
    "                     ('clf', LogisticRegression(solver='lbfgs', max_iter=20000))])\n",
    "\n",
    "parameters = {\n",
    "    'countvectorizer__max_features': (2500, 5000, 1000, 15000, 20000),\n",
    "    'countvectorizer__ngram_range': ((1,1), (2,2))\n",
    "}\n",
    "gs_clf = GridSearchCV(pipeline, parameters, cv=5)\n",
    "gs_clf_mdoel = gs_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9aa7c78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gs_clf_mdoel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "819b95f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98     28566\n",
      "           1       0.86      0.68      0.76      3338\n",
      "\n",
      "    accuracy                           0.96     31904\n",
      "   macro avg       0.91      0.84      0.87     31904\n",
      "weighted avg       0.95      0.96      0.95     31904\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "eaf18d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = gs_clf_mdoel.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7d8b89a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99    114726\n",
      "           1       0.96      0.78      0.86     12887\n",
      "\n",
      "    accuracy                           0.97    127613\n",
      "   macro avg       0.97      0.89      0.92    127613\n",
      "weighted avg       0.97      0.97      0.97    127613\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9d09ee56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('countvectorizer', CountVectorizer(max_features=20000)), ('clf', LogisticRegression(max_iter=20000))]\n"
     ]
    }
   ],
   "source": [
    "print(gs_clf_mdoel.best_estimator_.steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "906896a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_countvectorizer__max_features</th>\n",
       "      <th>param_countvectorizer__ngram_range</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.443439</td>\n",
       "      <td>0.660097</td>\n",
       "      <td>0.695917</td>\n",
       "      <td>0.067717</td>\n",
       "      <td>20000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'countvectorizer__max_features': 20000, 'coun...</td>\n",
       "      <td>0.956079</td>\n",
       "      <td>0.958782</td>\n",
       "      <td>0.956588</td>\n",
       "      <td>0.956508</td>\n",
       "      <td>0.956861</td>\n",
       "      <td>0.956964</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.603516</td>\n",
       "      <td>0.255752</td>\n",
       "      <td>0.621717</td>\n",
       "      <td>0.005848</td>\n",
       "      <td>15000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'countvectorizer__max_features': 15000, 'coun...</td>\n",
       "      <td>0.955099</td>\n",
       "      <td>0.959057</td>\n",
       "      <td>0.956392</td>\n",
       "      <td>0.956273</td>\n",
       "      <td>0.955960</td>\n",
       "      <td>0.956556</td>\n",
       "      <td>0.001329</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.755386</td>\n",
       "      <td>0.256373</td>\n",
       "      <td>0.606523</td>\n",
       "      <td>0.009012</td>\n",
       "      <td>5000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'countvectorizer__max_features': 5000, 'count...</td>\n",
       "      <td>0.954864</td>\n",
       "      <td>0.957999</td>\n",
       "      <td>0.954394</td>\n",
       "      <td>0.953883</td>\n",
       "      <td>0.954079</td>\n",
       "      <td>0.955044</td>\n",
       "      <td>0.001514</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.054140</td>\n",
       "      <td>0.514260</td>\n",
       "      <td>0.590120</td>\n",
       "      <td>0.018794</td>\n",
       "      <td>2500</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'countvectorizer__max_features': 2500, 'count...</td>\n",
       "      <td>0.953650</td>\n",
       "      <td>0.955452</td>\n",
       "      <td>0.952396</td>\n",
       "      <td>0.951493</td>\n",
       "      <td>0.952041</td>\n",
       "      <td>0.953006</td>\n",
       "      <td>0.001413</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.178097</td>\n",
       "      <td>0.465840</td>\n",
       "      <td>0.551079</td>\n",
       "      <td>0.004517</td>\n",
       "      <td>1000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'countvectorizer__max_features': 1000, 'count...</td>\n",
       "      <td>0.948517</td>\n",
       "      <td>0.950515</td>\n",
       "      <td>0.947302</td>\n",
       "      <td>0.947927</td>\n",
       "      <td>0.947771</td>\n",
       "      <td>0.948407</td>\n",
       "      <td>0.001124</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14.315039</td>\n",
       "      <td>2.002166</td>\n",
       "      <td>0.917382</td>\n",
       "      <td>0.096741</td>\n",
       "      <td>20000</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>{'countvectorizer__max_features': 20000, 'coun...</td>\n",
       "      <td>0.915018</td>\n",
       "      <td>0.916076</td>\n",
       "      <td>0.915096</td>\n",
       "      <td>0.915720</td>\n",
       "      <td>0.916660</td>\n",
       "      <td>0.915714</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13.376594</td>\n",
       "      <td>1.447049</td>\n",
       "      <td>0.948526</td>\n",
       "      <td>0.177171</td>\n",
       "      <td>15000</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>{'countvectorizer__max_features': 15000, 'coun...</td>\n",
       "      <td>0.912118</td>\n",
       "      <td>0.914234</td>\n",
       "      <td>0.912824</td>\n",
       "      <td>0.914544</td>\n",
       "      <td>0.914074</td>\n",
       "      <td>0.913559</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.277890</td>\n",
       "      <td>0.445875</td>\n",
       "      <td>0.880120</td>\n",
       "      <td>0.098344</td>\n",
       "      <td>5000</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>{'countvectorizer__max_features': 5000, 'count...</td>\n",
       "      <td>0.909219</td>\n",
       "      <td>0.909807</td>\n",
       "      <td>0.908749</td>\n",
       "      <td>0.908785</td>\n",
       "      <td>0.909568</td>\n",
       "      <td>0.909226</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.862666</td>\n",
       "      <td>0.514666</td>\n",
       "      <td>0.828159</td>\n",
       "      <td>0.037932</td>\n",
       "      <td>2500</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>{'countvectorizer__max_features': 2500, 'count...</td>\n",
       "      <td>0.908122</td>\n",
       "      <td>0.909180</td>\n",
       "      <td>0.907691</td>\n",
       "      <td>0.908236</td>\n",
       "      <td>0.908941</td>\n",
       "      <td>0.908434</td>\n",
       "      <td>0.000548</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11.315789</td>\n",
       "      <td>0.338314</td>\n",
       "      <td>0.804489</td>\n",
       "      <td>0.013253</td>\n",
       "      <td>1000</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>{'countvectorizer__max_features': 1000, 'count...</td>\n",
       "      <td>0.906633</td>\n",
       "      <td>0.907652</td>\n",
       "      <td>0.907103</td>\n",
       "      <td>0.907178</td>\n",
       "      <td>0.907570</td>\n",
       "      <td>0.907227</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "8       9.443439      0.660097         0.695917        0.067717   \n",
       "6       8.603516      0.255752         0.621717        0.005848   \n",
       "2       7.755386      0.256373         0.606523        0.009012   \n",
       "0       8.054140      0.514260         0.590120        0.018794   \n",
       "4       6.178097      0.465840         0.551079        0.004517   \n",
       "9      14.315039      2.002166         0.917382        0.096741   \n",
       "7      13.376594      1.447049         0.948526        0.177171   \n",
       "3      12.277890      0.445875         0.880120        0.098344   \n",
       "1      11.862666      0.514666         0.828159        0.037932   \n",
       "5      11.315789      0.338314         0.804489        0.013253   \n",
       "\n",
       "  param_countvectorizer__max_features param_countvectorizer__ngram_range  \\\n",
       "8                               20000                             (1, 1)   \n",
       "6                               15000                             (1, 1)   \n",
       "2                                5000                             (1, 1)   \n",
       "0                                2500                             (1, 1)   \n",
       "4                                1000                             (1, 1)   \n",
       "9                               20000                             (2, 2)   \n",
       "7                               15000                             (2, 2)   \n",
       "3                                5000                             (2, 2)   \n",
       "1                                2500                             (2, 2)   \n",
       "5                                1000                             (2, 2)   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "8  {'countvectorizer__max_features': 20000, 'coun...           0.956079   \n",
       "6  {'countvectorizer__max_features': 15000, 'coun...           0.955099   \n",
       "2  {'countvectorizer__max_features': 5000, 'count...           0.954864   \n",
       "0  {'countvectorizer__max_features': 2500, 'count...           0.953650   \n",
       "4  {'countvectorizer__max_features': 1000, 'count...           0.948517   \n",
       "9  {'countvectorizer__max_features': 20000, 'coun...           0.915018   \n",
       "7  {'countvectorizer__max_features': 15000, 'coun...           0.912118   \n",
       "3  {'countvectorizer__max_features': 5000, 'count...           0.909219   \n",
       "1  {'countvectorizer__max_features': 2500, 'count...           0.908122   \n",
       "5  {'countvectorizer__max_features': 1000, 'count...           0.906633   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "8           0.958782           0.956588           0.956508           0.956861   \n",
       "6           0.959057           0.956392           0.956273           0.955960   \n",
       "2           0.957999           0.954394           0.953883           0.954079   \n",
       "0           0.955452           0.952396           0.951493           0.952041   \n",
       "4           0.950515           0.947302           0.947927           0.947771   \n",
       "9           0.916076           0.915096           0.915720           0.916660   \n",
       "7           0.914234           0.912824           0.914544           0.914074   \n",
       "3           0.909807           0.908749           0.908785           0.909568   \n",
       "1           0.909180           0.907691           0.908236           0.908941   \n",
       "5           0.907652           0.907103           0.907178           0.907570   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "8         0.956964        0.000943                1  \n",
       "6         0.956556        0.001329                2  \n",
       "2         0.955044        0.001514                3  \n",
       "0         0.953006        0.001413                4  \n",
       "4         0.948407        0.001124                5  \n",
       "9         0.915714        0.000615                6  \n",
       "7         0.913559        0.000928                7  \n",
       "3         0.909226        0.000419                8  \n",
       "1         0.908434        0.000548                9  \n",
       "5         0.907227        0.000366               10  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gs_clf_mdoel.cv_results_).sort_values('mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1f17d9",
   "metadata": {},
   "source": [
    "# GridSearch with TF-IDF and Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0bde0fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['clean_text']\n",
    "y = df['toxic_type']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "56b07e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('tfidf', TfidfVectorizer()), \n",
    "                     ('clf', LogisticRegression(solver='lbfgs', max_iter=20000))])\n",
    "\n",
    "parameters = {\n",
    "    'tfidf__max_features': (2500, 5000, 1000, 15000, 20000),\n",
    "    'tfidf__ngram_range': ((1,1), (2,2))\n",
    "}\n",
    "tf_clf = GridSearchCV(pipeline, parameters, cv=5)\n",
    "tf_clf_model = gs_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bb2587a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = tf_clf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9cc6b41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98     28566\n",
      "           1       0.90      0.64      0.75      3338\n",
      "\n",
      "    accuracy                           0.95     31904\n",
      "   macro avg       0.93      0.81      0.86     31904\n",
      "weighted avg       0.95      0.95      0.95     31904\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a120121f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = tf_clf_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1b2fe190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98    114726\n",
      "           1       0.93      0.66      0.77     12887\n",
      "\n",
      "    accuracy                           0.96    127613\n",
      "   macro avg       0.95      0.83      0.87    127613\n",
      "weighted avg       0.96      0.96      0.96    127613\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "84b9509e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('tfidf', TfidfVectorizer(max_features=5000)), ('clf', LogisticRegression(max_iter=20000))]\n"
     ]
    }
   ],
   "source": [
    "print(tf_clf_model.best_estimator_.steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5386efc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_tfidf__max_features</th>\n",
       "      <th>param_tfidf__ngram_range</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.904038</td>\n",
       "      <td>0.446561</td>\n",
       "      <td>0.636236</td>\n",
       "      <td>0.072595</td>\n",
       "      <td>5000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'tfidf__max_features': 5000, 'tfidf__ngram_ra...</td>\n",
       "      <td>0.956196</td>\n",
       "      <td>0.958665</td>\n",
       "      <td>0.956314</td>\n",
       "      <td>0.957213</td>\n",
       "      <td>0.956155</td>\n",
       "      <td>0.956909</td>\n",
       "      <td>0.000960</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.674541</td>\n",
       "      <td>0.111841</td>\n",
       "      <td>0.604927</td>\n",
       "      <td>0.034133</td>\n",
       "      <td>15000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'tfidf__max_features': 15000, 'tfidf__ngram_r...</td>\n",
       "      <td>0.956627</td>\n",
       "      <td>0.957842</td>\n",
       "      <td>0.955883</td>\n",
       "      <td>0.956782</td>\n",
       "      <td>0.955724</td>\n",
       "      <td>0.956572</td>\n",
       "      <td>0.000755</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.661916</td>\n",
       "      <td>0.274466</td>\n",
       "      <td>0.586216</td>\n",
       "      <td>0.005234</td>\n",
       "      <td>20000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'tfidf__max_features': 20000, 'tfidf__ngram_r...</td>\n",
       "      <td>0.956353</td>\n",
       "      <td>0.957372</td>\n",
       "      <td>0.956196</td>\n",
       "      <td>0.956547</td>\n",
       "      <td>0.955803</td>\n",
       "      <td>0.956454</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.640266</td>\n",
       "      <td>0.070743</td>\n",
       "      <td>0.604778</td>\n",
       "      <td>0.032850</td>\n",
       "      <td>2500</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'tfidf__max_features': 2500, 'tfidf__ngram_ra...</td>\n",
       "      <td>0.954903</td>\n",
       "      <td>0.957646</td>\n",
       "      <td>0.954786</td>\n",
       "      <td>0.954157</td>\n",
       "      <td>0.954118</td>\n",
       "      <td>0.955122</td>\n",
       "      <td>0.001302</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.220113</td>\n",
       "      <td>0.055676</td>\n",
       "      <td>0.544155</td>\n",
       "      <td>0.013458</td>\n",
       "      <td>1000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'tfidf__max_features': 1000, 'tfidf__ngram_ra...</td>\n",
       "      <td>0.950398</td>\n",
       "      <td>0.950672</td>\n",
       "      <td>0.949261</td>\n",
       "      <td>0.950866</td>\n",
       "      <td>0.950357</td>\n",
       "      <td>0.950311</td>\n",
       "      <td>0.000557</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.993143</td>\n",
       "      <td>0.048513</td>\n",
       "      <td>0.860431</td>\n",
       "      <td>0.025296</td>\n",
       "      <td>20000</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>{'tfidf__max_features': 20000, 'tfidf__ngram_r...</td>\n",
       "      <td>0.914156</td>\n",
       "      <td>0.915527</td>\n",
       "      <td>0.915057</td>\n",
       "      <td>0.915250</td>\n",
       "      <td>0.915602</td>\n",
       "      <td>0.915118</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9.821631</td>\n",
       "      <td>0.140152</td>\n",
       "      <td>0.846451</td>\n",
       "      <td>0.036268</td>\n",
       "      <td>15000</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>{'tfidf__max_features': 15000, 'tfidf__ngram_r...</td>\n",
       "      <td>0.912824</td>\n",
       "      <td>0.915096</td>\n",
       "      <td>0.913842</td>\n",
       "      <td>0.914270</td>\n",
       "      <td>0.913721</td>\n",
       "      <td>0.913951</td>\n",
       "      <td>0.000741</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.072934</td>\n",
       "      <td>0.470357</td>\n",
       "      <td>0.870955</td>\n",
       "      <td>0.073766</td>\n",
       "      <td>5000</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>{'tfidf__max_features': 5000, 'tfidf__ngram_ra...</td>\n",
       "      <td>0.909297</td>\n",
       "      <td>0.909846</td>\n",
       "      <td>0.908592</td>\n",
       "      <td>0.909137</td>\n",
       "      <td>0.908941</td>\n",
       "      <td>0.909163</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.655236</td>\n",
       "      <td>0.349900</td>\n",
       "      <td>0.785197</td>\n",
       "      <td>0.038589</td>\n",
       "      <td>2500</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>{'tfidf__max_features': 2500, 'tfidf__ngram_ra...</td>\n",
       "      <td>0.908200</td>\n",
       "      <td>0.908553</td>\n",
       "      <td>0.908122</td>\n",
       "      <td>0.908040</td>\n",
       "      <td>0.908040</td>\n",
       "      <td>0.908191</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.409683</td>\n",
       "      <td>0.167591</td>\n",
       "      <td>0.749158</td>\n",
       "      <td>0.010880</td>\n",
       "      <td>1000</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>{'tfidf__max_features': 1000, 'tfidf__ngram_ra...</td>\n",
       "      <td>0.907143</td>\n",
       "      <td>0.907417</td>\n",
       "      <td>0.906986</td>\n",
       "      <td>0.906708</td>\n",
       "      <td>0.906982</td>\n",
       "      <td>0.907047</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "2       3.904038      0.446561         0.636236        0.072595   \n",
       "6       3.674541      0.111841         0.604927        0.034133   \n",
       "8       3.661916      0.274466         0.586216        0.005234   \n",
       "0       3.640266      0.070743         0.604778        0.032850   \n",
       "4       3.220113      0.055676         0.544155        0.013458   \n",
       "9       9.993143      0.048513         0.860431        0.025296   \n",
       "7       9.821631      0.140152         0.846451        0.036268   \n",
       "3      10.072934      0.470357         0.870955        0.073766   \n",
       "1       9.655236      0.349900         0.785197        0.038589   \n",
       "5       9.409683      0.167591         0.749158        0.010880   \n",
       "\n",
       "  param_tfidf__max_features param_tfidf__ngram_range  \\\n",
       "2                      5000                   (1, 1)   \n",
       "6                     15000                   (1, 1)   \n",
       "8                     20000                   (1, 1)   \n",
       "0                      2500                   (1, 1)   \n",
       "4                      1000                   (1, 1)   \n",
       "9                     20000                   (2, 2)   \n",
       "7                     15000                   (2, 2)   \n",
       "3                      5000                   (2, 2)   \n",
       "1                      2500                   (2, 2)   \n",
       "5                      1000                   (2, 2)   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "2  {'tfidf__max_features': 5000, 'tfidf__ngram_ra...           0.956196   \n",
       "6  {'tfidf__max_features': 15000, 'tfidf__ngram_r...           0.956627   \n",
       "8  {'tfidf__max_features': 20000, 'tfidf__ngram_r...           0.956353   \n",
       "0  {'tfidf__max_features': 2500, 'tfidf__ngram_ra...           0.954903   \n",
       "4  {'tfidf__max_features': 1000, 'tfidf__ngram_ra...           0.950398   \n",
       "9  {'tfidf__max_features': 20000, 'tfidf__ngram_r...           0.914156   \n",
       "7  {'tfidf__max_features': 15000, 'tfidf__ngram_r...           0.912824   \n",
       "3  {'tfidf__max_features': 5000, 'tfidf__ngram_ra...           0.909297   \n",
       "1  {'tfidf__max_features': 2500, 'tfidf__ngram_ra...           0.908200   \n",
       "5  {'tfidf__max_features': 1000, 'tfidf__ngram_ra...           0.907143   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "2           0.958665           0.956314           0.957213           0.956155   \n",
       "6           0.957842           0.955883           0.956782           0.955724   \n",
       "8           0.957372           0.956196           0.956547           0.955803   \n",
       "0           0.957646           0.954786           0.954157           0.954118   \n",
       "4           0.950672           0.949261           0.950866           0.950357   \n",
       "9           0.915527           0.915057           0.915250           0.915602   \n",
       "7           0.915096           0.913842           0.914270           0.913721   \n",
       "3           0.909846           0.908592           0.909137           0.908941   \n",
       "1           0.908553           0.908122           0.908040           0.908040   \n",
       "5           0.907417           0.906986           0.906708           0.906982   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "2         0.956909        0.000960                1  \n",
       "6         0.956572        0.000755                2  \n",
       "8         0.956454        0.000520                3  \n",
       "0         0.955122        0.001302                4  \n",
       "4         0.950311        0.000557                5  \n",
       "9         0.915118        0.000519                6  \n",
       "7         0.913951        0.000741                7  \n",
       "3         0.909163        0.000415                8  \n",
       "1         0.908191        0.000191                9  \n",
       "5         0.907047        0.000232               10  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tf_clf_model.cv_results_).sort_values('mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db17ae11",
   "metadata": {},
   "source": [
    "The performance of TF-IDF is similar to countvectorizer but with lower number of features than BOW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4934c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
